{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment - Compare BLS model performance with historical datasets and data aggregation.\n",
    "* This is an experimental idea that aggregate data points on longer time span than just one minute will improve performance and stability for any models other than RNN, especially in Fscore. \n",
    "* It is based on the thinking: An anomaly should and can only be determined by the features acrossing a rather large time span. The features extracted from the messages within only one minute are not enough to determine if there is an anomaly in this minute of time.   \n",
    "* In this experiment, Aggregation of some time spans from 1 to 60 will be tested and the according mesurements (accuracy and fscore) will be compared.  \n",
    "* You can specify time span and select datasets one by one, or run many tests with different parameters as a batch (integrated run) to observe the trend at the last step. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Switch between the following time spans to compare the results\n",
    "time_span = 1\n",
    "# time_span = 2\n",
    "# time_span = 3\n",
    "# time_span = 4\n",
    "# time_span = 5\n",
    "# time_span = 6\n",
    "# time_span = 7\n",
    "# time_span = 8\n",
    "# time_span = 9\n",
    "# time_span = 10\n",
    "# time_span = 20\n",
    "# time_span = 30\n",
    "# time_span = 40\n",
    "# time_span = 60\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load the datasets\n",
    "path_app = \"src\"\n",
    "dataset0 = np.loadtxt(\"./%s/data_historical/Code_Red_I.csv\" % path_app, delimiter=\",\")\n",
    "dataset1 = np.loadtxt(\"./%s/data_historical/Nimda.csv\" % path_app, delimiter=\",\")\n",
    "dataset2 = np.loadtxt(\"./%s/data_historical/Slammer.csv\" % path_app, delimiter=\",\")\n",
    "dataset3 = np.loadtxt(\"./%s/data_historical/Moscow_blackout.csv\" % path_app, delimiter=\",\")\n",
    "dataset4 = np.loadtxt(\"./%s/data_historical/WannaCrypt.csv\" % path_app, delimiter=\",\")\n",
    "dataset5 = np.loadtxt(\"./%s/data_historical/RIPE_regular.csv\" % path_app, delimiter=\",\")\n",
    "dataset6 = np.loadtxt(\"./%s/data_historical/BCNET_regular.csv\" % path_app, delimiter=\",\")\n",
    "datasets = {\"Code_Red_I\": dataset0, \"Nimda\": dataset1, \"Slammer\": dataset2, \"Moscow_blackout\": dataset3, \"WannaCrypt\": dataset4, \"RIPE_regular\": dataset5, \"BCNET_regular\": dataset6}\n",
    "\n",
    "# Select datasets\n",
    "raw_train_datasets = [datasets[\"Code_Red_I\"], datasets[\"Nimda\"]]\n",
    "raw_test_dataset = datasets[\"Slammer\"]\n",
    "\n",
    "# raw_train_datasets = [datasets[\"Nimda\"], datasets[\"Slammer\"]]\n",
    "# raw_test_dataset = datasets[\"Code_Red_I\"]\n",
    "\n",
    "# raw_train_datasets = [datasets[\"Slammer\"], datasets[\"Code_Red_I\"]]\n",
    "# raw_test_dataset = datasets[\"Nimda\"]\n",
    "\n",
    "print(\"Raw training datasets shape: \", [x.shape for x in raw_train_datasets])\n",
    "print(\"Raw training labels of regular and anomaly: \", [(np.sum(x[:,-1]==-1, axis=0), np.sum(x[:,-1]==1, axis=0)) for x in raw_train_datasets])\n",
    "print(\"Raw test dataset shape: \", raw_test_dataset.shape)\n",
    "print(\"Raw test labels of regular and anomaly: \", np.sum(raw_test_dataset[:,-1]==-1, axis=0), np.sum(raw_test_dataset[:,-1]==1, axis=0))\n",
    "# print(raw_test_dataset[3206:3220, 4:16])\n",
    "# print(raw_test_dataset[3206:3220, -1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate data points\n",
    "According to the feature definition, apply different aggregation function to different column.  \n",
    "See src/xpr_feature_reshaping.py for explaination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.xpr_feature_reshaping import aggregate_datasets, aggregate_rows\n",
    "\n",
    "train_datasets = aggregate_datasets(raw_train_datasets, time_span)\n",
    "test_dataset = aggregate_rows(raw_test_dataset, time_span)\n",
    "\n",
    "print(\"Aggregated training datasets shape: \", [x.shape for x in train_datasets])\n",
    "print(\"Aggregated training labels of regular and anomaly: \", [(np.sum(x[:,-1]==-1, axis=0), np.sum(x[:,-1]==1, axis=0)) for x in train_datasets])\n",
    "print(\"Aggregated test dataset shape: \", test_dataset.shape)\n",
    "print(\"Aggregated test labels of regular and anomaly: \", np.sum(test_dataset[:,-1]==-1, axis=0), np.sum(test_dataset[:,-1]==1, axis=0))\n",
    "# print(test_dataset[1603:1613, 4:16])\n",
    "# print(test_dataset[1603:1613, -1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenate_datasets(datasets):\n",
    "    result = datasets[0]\n",
    "    for dataset in datasets[1:]:\n",
    "        result = np.concatenate((result, dataset), axis=0)\n",
    "    return result\n",
    "\n",
    "train_dataset = concatenate_datasets(train_datasets)\n",
    "\n",
    "print(\"Training dataset shape: \", train_dataset.shape)\n",
    "print(\"Training labels of regular and anomaly: \", np.sum(train_dataset[:,-1]==-1, axis=0), np.sum(train_dataset[:,-1]==1, axis=0))\n",
    "print(\"Test dataset shape: \", test_dataset.shape)\n",
    "print(\"Test labels of regular and anomaly: \", np.sum(test_dataset[:,-1]==-1, axis=0), np.sum(test_dataset[:,-1]==1, axis=0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select features\n",
    "Select some features instead of using all 37 features to observe how the performance changes. Default is to select all of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Must keep the first 4 of time stamps and the last one of the label in this step.\n",
    "def select_features(train_dataset, test_dataset):\n",
    "    # features_to_keep=[0, 1, 2, 3, 41]\n",
    "    features = [x for x in range(42)]\n",
    "\n",
    "    train_dataset = train_dataset[:, features]\n",
    "    test_dataset = test_dataset[:, features]\n",
    "    return train_dataset, test_dataset\n",
    "\n",
    "train_dataset, test_dataset = select_features(train_dataset, test_dataset)\n",
    "print(\"Training dataset shape: \", train_dataset.shape)\n",
    "print(\"Test dataset shape: \", test_dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./src/VFBLS_v110')\n",
    "from scipy.stats import zscore\n",
    "from bls.processing.replaceNan import replaceNan\n",
    "\n",
    "def normalize(dataset, div = 1 ):\n",
    "    row_index_end = dataset.shape[0] - dataset.shape[0] % div  # divisible by div, but What is div for?\n",
    "    data_x = dataset[:row_index_end, 4:-1]\n",
    "    data_x = zscore(data_x, axis=0, ddof=1)  # For each feature, mean = 0 and std = 1\n",
    "    replaceNan(data_x)  # Replace \"nan\" with 0\n",
    "    data_y = dataset[:row_index_end, -1]\n",
    "    # Change training labels\n",
    "    inds1 = np.where(data_y == -1)\n",
    "    data_y[inds1] = 2\n",
    "    return data_x,data_y\n",
    "\n",
    "train_x, train_y = normalize(train_dataset)\n",
    "test_x, test_y = normalize(test_dataset)\n",
    "\n",
    "print(\"Training dataset shape: \", train_x.shape)\n",
    "print(\"Training labels of regular and anomaly: \", np.sum(train_y==2), np.sum(train_y==1))\n",
    "print(\"Test dataset shape: \", test_x.shape)\n",
    "print(\"Test labels of regular and anomaly: \", np.sum(test_y==2), np.sum(test_y==1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select top features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bls.processing.feature_select_imp_cnl import feature_select_imp_cnl\n",
    "\n",
    "def top_features(train_x, train_y):\n",
    "    # num_features = 5\n",
    "    # features, _ = feature_select_imp_cnl(train_x, train_y, num_features)\n",
    "    features = [x for x in range(train_x.shape[1])] # Defaut to use all features    \n",
    "    return features\n",
    "\n",
    "top = top_features(train_x, train_y)\n",
    "train_x = train_x[:, top]\n",
    "test_x = test_x[:, top]\n",
    "print(\"Features: \", top)\n",
    "print(\"Training dataset shape: \", train_x.shape)\n",
    "print(\"Test dataset shape: \", test_x.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.VFBLS_v110.bls.processing.one_hot_m import one_hot_m\n",
    "from src.VFBLS_v110.bls.model.bls_train import bls_train_realtime\n",
    "\n",
    "print(\"======================= BLS =======================\\n\")\n",
    "def train_test(train_x, train_y, test_x):\n",
    "    # Set parameters\n",
    "    mem = 'low'\n",
    "    # mem = 'high'\n",
    "    # BLS parameters\n",
    "    seed = 1  # set the seed for generating random numbers\n",
    "    num_class = 2  # number of the classes\n",
    "    epochs = 1  # number of epochs\n",
    "    C = 2 ** -15  # parameter for sparse regularization\n",
    "    s = 0.6  # the shrinkage parameter for enhancement nodes\n",
    "    train_y = one_hot_m(train_y, num_class)\n",
    "    # test_y = one_hot_m(test_y, num_class);\n",
    "    #######################\n",
    "    # N1* - the number of mapped feature nodes\n",
    "    # N2* - the groups of mapped features\n",
    "    # N3* - the number of enhancement nodes\n",
    "    if mem == 'low':\n",
    "        N1_bls = 20\n",
    "        N2_bls = 5\n",
    "        N3_bls = 100\n",
    "    else:\n",
    "        N1_bls = 200\n",
    "        N2_bls = 10\n",
    "        N3_bls = 100\n",
    "    #######################\n",
    "\n",
    "    train_err = np.zeros((1, epochs))\n",
    "    train_time = np.zeros((1, epochs))\n",
    "    test_time = np.zeros((1, epochs))\n",
    "    np.random.seed(seed)  # set the seed for generating random numbers\n",
    "    for j in range(0, epochs):\n",
    "        trainingAccuracy, trainingTime, testingTime, predicted = \\\n",
    "        bls_train_realtime(train_x, train_y, test_x,\n",
    "                            s, C,\n",
    "                            N1_bls, N2_bls, N3_bls)\n",
    "\n",
    "        train_err[0, j] = trainingAccuracy * 100\n",
    "        train_time[0, j] = trainingTime\n",
    "        test_time[0, j] = testingTime\n",
    "    # predicted = [[1.], [2.], [2.], [2.], [2.]]\n",
    "    predicted_list = []\n",
    "    for label in predicted:\n",
    "        predicted_list.append(label[0])\n",
    "    return predicted_list\n",
    "\n",
    "predicted_list = train_test(train_x, train_y, test_x)\n",
    "\n",
    "print(\"predicted_list:\", predicted_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Accuracy and Fscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = accuracy_score(test_y, predicted_list)\n",
    "fscore = f1_score(test_y, predicted_list)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2%}, Fscore: {fscore:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Integrated run\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.1 Run with batch parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def blockPrint():\n",
    "    old_stdout = sys.stdout\n",
    "    sys.stdout = open(os.devnull, 'w')\n",
    "    return old_stdout\n",
    "def enablePrint(old_stdout):\n",
    "    sys.stdout = old_stdout\n",
    "\n",
    "time_span_list = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20, 25, 30, 40, 50, 60]\n",
    "data_combos = [{\"train\": [\"Code_Red_I\", \"Nimda\"], \"test\": \"Slammer\"},\n",
    "                {\"train\": [\"Nimda\", \"Slammer\"], \"test\": \"Code_Red_I\"},\n",
    "                {\"train\": [\"Code_Red_I\", \"Slammer\"], \"test\": \"Nimda\"},\n",
    "                {\"train\": [\"Code_Red_I\", \"Nimda\", \"Slammer\"], \"test\": \"Moscow_blackout\"},]\n",
    "# all_datasets = [\"Code_Red_I\", \"Nimda\", \"Slammer\", \"Moscow_blackout\", \"WannaCrypt\", \"RIPE_regular\", \"BCNET_regular\"]\n",
    "\n",
    "results = []\n",
    "for combo in data_combos:\n",
    "    raw_train_datasets = []\n",
    "    for name in combo[\"train\"]:\n",
    "        raw_train_datasets.append(datasets[name])\n",
    "    raw_test_dataset = datasets[combo[\"test\"]]\n",
    "    print(f\"Data combo: {combo}\")\n",
    "    print(\"Raw training datasets shape: \", [x.shape for x in raw_train_datasets])\n",
    "    print(\"Raw training labels of regular and anomaly: \", [(np.sum(x[:,-1]==-1, axis=0), np.sum(x[:,-1]==1, axis=0)) for x in raw_train_datasets])\n",
    "    print(\"Raw test dataset shape: \", raw_test_dataset.shape)\n",
    "    print(\"Raw test labels of regular and anomaly: \", np.sum(raw_test_dataset[:,-1]==-1, axis=0), np.sum(raw_test_dataset[:,-1]==1, axis=0))\n",
    "    for time_span in time_span_list:\n",
    "        train_datasets = aggregate_datasets(raw_train_datasets, time_span)\n",
    "        test_dataset = aggregate_rows(datasets[combo[\"test\"]], time_span)\n",
    "        train_dataset = concatenate_datasets(train_datasets)\n",
    "        train_dataset, test_dataset = select_features(train_dataset, test_dataset)\n",
    "        train_x, train_y = normalize(train_dataset)\n",
    "        test_x, test_y = normalize(test_dataset)\n",
    "        old_stdout = blockPrint()\n",
    "        top = top_features(train_x, train_y)\n",
    "        train_x = train_x[:, top]\n",
    "        test_x = test_x[:, top]\n",
    "        predicted_list = train_test(train_x, train_y, test_x)\n",
    "        enablePrint(old_stdout)\n",
    "        accuracy = accuracy_score(test_y, predicted_list)\n",
    "        fscore = f1_score(test_y, predicted_list)\n",
    "        row = [\"+\".join(combo[\"train\"]), combo[\"test\"], f\"{time_span}\", f\"{accuracy*100:.2f}\", f\"{fscore*100:.2f}\"]\n",
    "        # row = [\"+\".join(combo[\"train\"]), combo[\"test\"], time_span, accuracy*100, fscore*100]\n",
    "        results.append(row)\n",
    "        print(f\"Time span: {time_span} - Accuracy: {accuracy:.2%}, Fscore: {fscore:.2%}\")\n",
    "\n",
    "# Save the results\n",
    "file_name = \"src/STAT/xpr_results.csv\" \n",
    "# np.savetxt(\"xpr_results.csv\", results, delimiter=\",\", fmt=\"%s,%s,%f,%f,%f\")\n",
    "results.insert(0, [\"Train datasets\", \"Test datasets\", \"Time span\", \"Accuracy %\", \"Fscore %\"])\n",
    "results = np.array(results)\n",
    "np.savetxt(file_name, results, delimiter=\",\", fmt=\"%s\")\n",
    "print(\"Results saved to\", file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.2 Plot the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot each series in a subplot\n",
    "def subplot(label, series, ax, data_column):\n",
    "    for series in series:\n",
    "        mask = np.array([row[1] == series for row in results])\n",
    "        x = results[mask, 2].astype(int)\n",
    "        y = results[mask, data_column].astype(float)\n",
    "        line = ax.plot(x, y, label=series)[0]\n",
    "        \n",
    "        # Add annotation for the point of baseline\n",
    "        ax.annotate(f'{y[0]:.2f}', xy=(x[0], y[0]), xytext=(x[0] + 2, y[0]),\n",
    "                    color=ax.lines[-1].get_color(), arrowprops=dict(arrowstyle='->'))\n",
    "        \n",
    "        # Find the index of the maximum value in y\n",
    "        max_idx = np.argmax(y)\n",
    "        max_x = x[max_idx]\n",
    "        max_y = y[max_idx]\n",
    "        \n",
    "        # Draw a vertical line at the maximum value\n",
    "        ax.axvline(x=max_x, color=ax.lines[-1].get_color(), linestyle='--')\n",
    "        \n",
    "        # Annotate the maximum value\n",
    "        ax.annotate(f'{max_y:.2f}', xy=(max_x, max_y), xytext=(max_x + 1, max_y),\n",
    "                    color=ax.lines[-1].get_color(), arrowprops=dict(arrowstyle='->'))\n",
    "    \n",
    "    ax.set_xlabel('Time Span')\n",
    "    ax.set_ylabel(label)\n",
    "    ax.set_xlim(left=1)\n",
    "    ax.set_xticks(time_span_list)\n",
    "    ax.legend()\n",
    "    # fig.suptitle('Comparison of different time spans')\n",
    "\n",
    "series = np.unique(results[1:, 1])\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "subplot('Accuracy', series, ax1, 3)\n",
    "subplot('Fscore', series, ax2, 4)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
